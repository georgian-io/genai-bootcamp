{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 (Optional): Use Langfuse to track evaluation and trace\n",
    "\n",
    "This notebook uses langfuse to trace and track the evaluation. You need an API key to run this notebook. Langfuse offers a free tier with 50,000 observations per month (as of June 2024). This notebook uses approximately 50 observations. You can get the API key by signing up on https://cloud.langfuse.com, creating a new project, and creating a new API key in the settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "100%|██████████| 5/5 [00:00<00:00, 3591.63it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840dc9343ba242aeb8391cd0f9ded8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents before chunking: 5\n",
      "Documents after chunking: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashsaravanan/Library/Caches/pypoetry/virtualenvs/genai-bootcamp-4wh1UwyX-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Plain maskray = \n",
      " \n",
      " The plain maskray or brown stingray ( Neotrygon annotata ) is a species of stingray in the family Dasyatidae . It is found in shallow , soft-bottomed habitats off northern Australia . Reaching 24 cm ( 9.4 in ) in width , this species has a diamond-shaped , grayish green pectoral fin disc . Its short , whip-like tail has alternating black and white bands and fin folds above and below . There are short rows of thorns on the back and the base of the tail , but otherwise the s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0442ca19774e8da4d653b4d6e768c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plain maskray is found in the continental shelf of northern Australia, from the Wellesley Islands in Queensland to the Bonaparte Archipelago in Western Australia, including the Gulf of Carpentaria and the Timor and Arafura Seas. There are also unsubstantiated reports that its range extends to southern Papua New Guinea.\n",
      "\n",
      "Source: Plain maskray\n",
      "Relevant Snippet: \"The plain maskray inhabits the continental shelf of northern Australia from the Wellesley Islands in Queensland to the Bonaparte Archipelago in Western Australia, including the Gulf of Carpentaria and the Timor and Arafura Seas. There are unsubstantiated reports that its range extends to southern Papua New Guinea.\"\n"
     ]
    }
   ],
   "source": [
    "%run 01-llm-app-setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your keys if you didn't put it in your \".env\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get keys for your project from https://cloud.langfuse.com\n",
    "# Set them here if not set in .env\n",
    "# import os\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from langfuse import Langfuse\n",
    "import openai\n",
    " \n",
    "# init\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gen_dataset = pd.read_csv(\"generated_qa.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RAG QA Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse.create_dataset(name=dataset_name)\n",
    "\n",
    "# Upload to Langfuse\n",
    "for _, row in gen_dataset.iterrows():\n",
    "  langfuse.create_dataset_item(\n",
    "      dataset_name=dataset_name,\n",
    "      # any python object or value\n",
    "      input=row[\"question\"],\n",
    "      # any python object or value, optional\n",
    "      expected_output={\n",
    "        \"ground_truth\": row[\"ground_truth\"],\n",
    "        \"ground_truth_context\": row[\"ground_truth_context\"]\n",
    "      }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup custom evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 03-metrics-definition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf_context_correctness(output, expected_output):\n",
    "    ground_truth_context = expected_output[\"ground_truth_context\"]\n",
    "    retrieved_contexts = output[\"context\"] or []\n",
    "    return context_correctness(ground_truth_context, retrieved_contexts)\n",
    "\n",
    "\n",
    "def lf_ground_truth_context_rank(output, expected_output):\n",
    "    ground_truth_context = expected_output[\"ground_truth_context\"]\n",
    "    retrieved_contexts = output[\"context\"] or []\n",
    "    return ground_truth_context_rank(ground_truth_context, retrieved_contexts)\n",
    "\n",
    "\n",
    "def lf_context_rougel_score(output, expected_output):\n",
    "    ground_truth_context = expected_output[\"ground_truth_context\"]\n",
    "    retrieved_contexts = output[\"context\"] or []\n",
    "    return context_rougel_score(ground_truth_context, retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    " \n",
    "def run_my_custom_llm_app(input):\n",
    "    generationStartTime = datetime.now()\n",
    "\n",
    "    model_output = openai_query_engine.query(input)\n",
    "    response = model_output.response\n",
    "    context = [node.text for node in model_output.source_nodes]\n",
    "    formatted_output = {\n",
    "        \"output\": response,\n",
    "        \"context\": context\n",
    "    }\n",
    "    \n",
    "    langfuse_generation = langfuse.generation(\n",
    "        name=\"rag-chain-qa\",\n",
    "        input=input,\n",
    "        output=formatted_output,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        start_time=generationStartTime,\n",
    "        end_time=datetime.now()\n",
    "        )\n",
    "\n",
    "    return formatted_output, langfuse_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = langfuse.get_dataset(dataset_name)\n",
    "\n",
    "for item in dataset.items:\n",
    "    completion, langfuse_generation = run_my_custom_llm_app(item.input)\n",
    "\n",
    "    item.link(langfuse_generation, \"Exp 1\")\n",
    "\n",
    "    langfuse_generation.score(\n",
    "        name=\"context_correctness\",\n",
    "        value=lf_context_correctness(completion, item.expected_output)\n",
    "        )\n",
    "    langfuse_generation.score(\n",
    "        name=\"context_rank\",\n",
    "        value=lf_ground_truth_context_rank(completion, item.expected_output)\n",
    "        )\n",
    "    langfuse_generation.score(\n",
    "        name=\"context_rougel_score\",\n",
    "        value=lf_context_rougel_score(completion, item.expected_output)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please go to https://cloud.langfuse.com/ to see the trace and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of LangFuse as of July 12 2024](langfuse.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
