{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluate the application\n",
    "\n",
    "## 1. Run the app on our evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "100%|██████████| 5/5 [00:00<00:00, 1915.03it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a0ab6cec864787a2d475dc8205da5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents before chunking: 5\n",
      "Documents after chunking: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashsaravanan/Library/Caches/pypoetry/virtualenvs/genai-bootcamp-4wh1UwyX-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Plain maskray = \n",
      " \n",
      " The plain maskray or brown stingray ( Neotrygon annotata ) is a species of stingray in the family Dasyatidae . It is found in shallow , soft-bottomed habitats off northern Australia . Reaching 24 cm ( 9.4 in ) in width , this species has a diamond-shaped , grayish green pectoral fin disc . Its short , whip-like tail has alternating black and white bands and fin folds above and below . There are short rows of thorns on the back and the base of the tail , but otherwise the s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83573c28d56a46c4910d62e2afdd890f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plain maskray is found in the continental shelf of northern Australia from the Wellesley Islands in Queensland to the Bonaparte Archipelago in Western Australia, including the Gulf of Carpentaria and the Timor and Arafura Seas. There are also unsubstantiated reports that its range extends to southern Papua New Guinea.\n",
      "\n",
      "Source: Plain maskray\n",
      "Relevant Snippet: \"The plain maskray inhabits the continental shelf of northern Australia from the Wellesley Islands in Queensland to the Bonaparte Archipelago in Western Australia, including the Gulf of Carpentaria and the Timor and Arafura Seas. There are unsubstantiated reports that its range extends to southern Papua New Guinea.\"\n"
     ]
    }
   ],
   "source": [
    "%run 01-llm-app-setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gen_dataset = pd.read_csv('generated_qa.csv')\n",
    "# Running only on 5 items for speed\n",
    "sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset[\"answer\"] = None\n",
    "gen_dataset[\"contexts\"] = None\n",
    "\n",
    "for idx, item in gen_dataset.iloc[:sample_size].iterrows():\n",
    "    result = openai_query_engine.query(item.question)\n",
    "    gen_dataset.at[idx, \"answer\"] = result.response\n",
    "    gen_dataset.at[idx, \"contexts\"] = [node.text for node in result.source_nodes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>ground_truth_context</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the full Japanese title of Valkyria Ch...</td>\n",
       "      <td>Senjō no Valkyria 3: Unrecorded Chronicles (Ja...</td>\n",
       "      <td>= Valkyria Chronicles III = \\n \\n Senjō no Val...</td>\n",
       "      <td>The full Japanese title of Valkyria Chronicles...</td>\n",
       "      <td>[= Valkyria Chronicles III = \\n \\n Senjō no Va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the main progression system in the game?</td>\n",
       "      <td>The player progresses through a series of line...</td>\n",
       "      <td>The player progresses through a series of line...</td>\n",
       "      <td>The main progression system in \"Valkyria Chron...</td>\n",
       "      <td>[The player progresses through a series of lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the five classes of troops mentioned ...</td>\n",
       "      <td>The five classes of troops are Scouts, Shocktr...</td>\n",
       "      <td>Troops are divided into five classes : Scouts ...</td>\n",
       "      <td>The five classes of troops mentioned in the te...</td>\n",
       "      <td>[Troops are divided into five classes : Scouts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the commanding officer of the Nameless?</td>\n",
       "      <td>Ramsey Crowe</td>\n",
       "      <td>Hounded by both allies and enemies , and combi...</td>\n",
       "      <td>The commanding officer of the Nameless is Rams...</td>\n",
       "      <td>[Hounded by both allies and enemies , and comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was Valkyria Chronicles III developed for ...</td>\n",
       "      <td>The team wanted to refine the mechanics create...</td>\n",
       "      <td>Like its predecessor , Valkyria Chronicles III...</td>\n",
       "      <td>Valkyria Chronicles III was developed for the ...</td>\n",
       "      <td>[Like its predecessor , Valkyria Chronicles II...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the full Japanese title of Valkyria Ch...   \n",
       "1   What is the main progression system in the game?   \n",
       "2  What are the five classes of troops mentioned ...   \n",
       "3     Who is the commanding officer of the Nameless?   \n",
       "4  Why was Valkyria Chronicles III developed for ...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Senjō no Valkyria 3: Unrecorded Chronicles (Ja...   \n",
       "1  The player progresses through a series of line...   \n",
       "2  The five classes of troops are Scouts, Shocktr...   \n",
       "3                                       Ramsey Crowe   \n",
       "4  The team wanted to refine the mechanics create...   \n",
       "\n",
       "                                ground_truth_context  \\\n",
       "0  = Valkyria Chronicles III = \\n \\n Senjō no Val...   \n",
       "1  The player progresses through a series of line...   \n",
       "2  Troops are divided into five classes : Scouts ...   \n",
       "3  Hounded by both allies and enemies , and combi...   \n",
       "4  Like its predecessor , Valkyria Chronicles III...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The full Japanese title of Valkyria Chronicles...   \n",
       "1  The main progression system in \"Valkyria Chron...   \n",
       "2  The five classes of troops mentioned in the te...   \n",
       "3  The commanding officer of the Nameless is Rams...   \n",
       "4  Valkyria Chronicles III was developed for the ...   \n",
       "\n",
       "                                            contexts  \n",
       "0  [= Valkyria Chronicles III = \\n \\n Senjō no Va...  \n",
       "1  [The player progresses through a series of lin...  \n",
       "2  [Troops are divided into five classes : Scouts...  \n",
       "3  [Hounded by both allies and enemies , and comb...  \n",
       "4  [Like its predecessor , Valkyria Chronicles II...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dataset.iloc[:sample_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run evaluation\n",
    "\n",
    "This might take a few minutes. We call our pre-defined evaluation functions and also run ragas on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 03-metrics-definition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f561b227130f4bd39babb44f847c3ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be2f89a18eb48009d033802c4a50bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5864dbf8054af8ac8e2f5278f8fa69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd0d6d7d774480aa183d292c885e906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7aecae5a554fd783f20343d94d328c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_lst = []\n",
    " \n",
    "for idx, row in gen_dataset.iloc[:sample_size].iterrows(): # Subsetting to make it go faster\n",
    "    custom_eval_results = {\n",
    "        \"context_correctness\": context_correctness(row[\"ground_truth_context\"], row[\"contexts\"]),\n",
    "        \"ground_truth_context_rank\": ground_truth_context_rank(row[\"ground_truth_context\"], row[\"contexts\"]),\n",
    "        \"context_rougel_score\": context_rougel_score(row[\"ground_truth_context\"], row[\"contexts\"]),\n",
    "    }\n",
    "\n",
    "    ragas_eval_results = evaluate_w_ragas(row)\n",
    "    results_lst.append(custom_eval_results | ragas_eval_results)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_correctness</th>\n",
       "      <th>ground_truth_context_rank</th>\n",
       "      <th>context_rougel_score</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.621889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.205459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_correctness  ground_truth_context_rank  context_rougel_score  \\\n",
       "0                 True                          0                   1.0   \n",
       "1                 True                          0                   1.0   \n",
       "2                 True                          0                   1.0   \n",
       "3                 True                          0                   1.0   \n",
       "4                 True                          0                   1.0   \n",
       "\n",
       "   context_precision  faithfulness  answer_correctness  \n",
       "0                1.0           1.0            0.988061  \n",
       "1                1.0           1.0            0.621889  \n",
       "2                1.0           1.0            0.989046  \n",
       "3                1.0           1.0            0.205459  \n",
       "4                1.0           1.0            0.725229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We can aggregate these metrics to get a single number for each of them and we have a good evaluation of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
