{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We've abstracted away the code from the previous notebooks to focus on the concepts from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_data(sample_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "We've abstracted away the code from the previous notebooks to focus on the concepts from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2900.73it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = utils.preprocess_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "We've abstracted away the code from the previous notebooks to focus on the concepts from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca12ae0f74fe476da17a3d2038c671a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents before chunking: 100\n",
      "Documents after chunking: 837\n"
     ]
    }
   ],
   "source": [
    "nodes = utils.chunk_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "We've abstracted away the code from the previous notebooks to focus on the concepts from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashsaravanan/Library/Caches/pypoetry/virtualenvs/genai-bootcamp-4wh1UwyX-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = utils.get_embedding_model(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "\n",
    "LlamaIndex stores embeddings in a [VectorStoreIndex](https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/) object. This can be used with any vector store [supported](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores/) by LlamaIndex. By default, this is a [SimpleIndex](https://docs.llamaindex.ai/en/stable/api_reference/storage/vector_store/simple/) which is a flat index. \n",
    "\n",
    "We load all our chunks and embed them when creating a VectorStoreIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d367dfcf65491ca211d91417184165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex(nodes, embed_model=embedding_model, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many points did Michael Jordan actually score in his final NBA game?\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 1: Michael Jordan (0.797218871120604)\n",
      "With the recognition that 2002 – 03 would be Jordan 's final season , tributes were paid to him thro...\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 2: Michael Jordan (0.7971195354652177)\n",
      "In an injury-plagued 2001 – 02 season , he led the team in scoring ( 22.9 ppg ) , assists ( 5.2 apg ...\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 3: Michael Jordan (0.7867602798002393)\n",
      "Jordan led the league with 28.7 points per game , securing his fifth regular-season MVP award , plus...\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"How many points did Michael Jordan actually score in his final NBA game?\"\n",
    "results = index.as_retriever(similarity_top_k=3).retrieve(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"---\" * 30)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Rank {i+1}: {result.metadata['title']} ({result.score})\")\n",
    "    print(result.text[:100] + \"...\")\n",
    "    print(\"---\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.5 ms ± 3.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "query = \"How many points did Michael Jordan actually score in his final NBA game?\"\n",
    "results = index.as_retriever(similarity_top_k=3).retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstore / Vector DB\n",
    "\n",
    "We use LanceDB, an embedded vector DB, instead of the default index used above. We use an embedded database as it's easier to setup and runs in-process. You can learn more about LanceDB [here](https://lancedb.github.io/lancedb/). As described [here](https://lancedb.github.io/lancedb/ann_indexes/), LanceDB uses a disk-based IVF-PQ index. It is noted on the site that this is usually only necessary when you have 100k+ samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/vector_stores/LanceDBIndexDemo/\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# Create your DB locally\n",
    "vector_store = LanceDBVectorStore(\n",
    "    uri=\"./lancedb\", table_name=\"test\"\n",
    ")\n",
    "# Link to the collection on llamaindex\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1603b7c12747c086bee780c16a99a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-13T23:35:30Z WARN  lance::dataset] No existing dataset at /Users/akashsaravanan/Downloads/GenAI Bootcamp/genai-bootcamp/notebooks/lancedb/test.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "# Embed and index\n",
    "vdb_index = VectorStoreIndex(nodes, embed_model=embedding_model, storage_context=storage_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many points did Michael Jordan actually score in his final NBA game?\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 1: Michael Jordan (0.6666018962860107)\n",
      "With the recognition that 2002 – 03 would be Jordan 's final season , tributes were paid to him thro...\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 2: Michael Jordan (0.6664695143699646)\n",
      "In an injury-plagued 2001 – 02 season , he led the team in scoring ( 22.9 ppg ) , assists ( 5.2 apg ...\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 3: Michael Jordan (0.6528033018112183)\n",
      "Jordan led the league with 28.7 points per game , securing his fifth regular-season MVP award , plus...\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"How many points did Michael Jordan actually score in his final NBA game?\"\n",
    "results = vdb_index.as_retriever(similarity_top_k=3).retrieve(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"---\" * 30)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Rank {i+1}: {result.metadata['title']} ({result.score})\")\n",
    "    print(result.text[:100] + \"...\")\n",
    "    print(\"---\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 ms ± 6.23 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "query = \"How many points did Michael Jordan actually score in his final NBA game?\"\n",
    "results = index.as_retriever(similarity_top_k=3).retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Index Disk Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_size(folder: str) -> int:\n",
    "    return sum(p.stat().st_size for p in Path(folder).rglob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is 2.2392 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Index is {get_size('lancedb/test.lance') / (1024 ** 3):.4f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-bootcamp-4wh1UwyX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
