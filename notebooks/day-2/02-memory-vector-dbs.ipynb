{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory and Vector Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy from day 1 - 05-example-entity-extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract key pieces of information from this regulation document.\n",
      "If a particular piece of information is not present, output \"Not specified\".\n",
      "When you extract a key piece of information, include the closest page number.\n",
      "Use the following format:\n",
      "0. What's the name of the company?\n",
      "1. Who are the founders of the company?\n",
      "2. When is it founded?\n",
      "3. When did it raise series A?\n",
      "Document: \"\"\"<document>\"\"\"\n",
      "\n",
      "0.\n"
     ]
    }
   ],
   "source": [
    "document = '<document>'\n",
    "template_prompt=f'''Extract key pieces of information from this regulation document.\n",
    "If a particular piece of information is not present, output \\\"Not specified\\\".\n",
    "When you extract a key piece of information, include the closest page number.\n",
    "Use the following format:\\n0. What's the name of the company?\\n1. Who are the founders of the company?\\n2. When is it founded?\\n3. When did it raise series A?\\nDocument: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\\n0.'''\n",
    "print(template_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_document = \"\"\"\n",
    "Overview:\n",
    "Tech Solutions Inc. is a leading technology consulting firm specializing in providing innovative solutions to businesses across various industries. We offer a comprehensive range of services including software development, IT consulting, project management, and cybersecurity solutions. \n",
    "With a strong focus on delivering exceptional quality and customer satisfaction, we have established ourselves as a trusted partner for organizations seeking digital transformation.\n",
    "They were founded on April 12, 2005 and raise their first seed in 2007 and series A on May 25, 2007.\n",
    "\n",
    "Founders:\n",
    "\n",
    "Background: John Smith is a visionary entrepreneur with over 20 years of experience in the technology industry. He has a deep understanding of market trends and has successfully led several software development projects for multinational corporations.\n",
    "Role in the Company: As a co-founder of Tech Solutions Inc., John Smith plays a pivotal role in shaping the company's strategic direction. His expertise in software development and leadership skills have been instrumental in driving the company's growth.\n",
    "Sarah Johnson:\n",
    "\n",
    "Background: Sarah Johnson is a highly accomplished technologist with a strong background in software engineering. She has extensive experience in managing complex IT projects and has a proven track record of delivering innovative solutions.\n",
    "Role in the Company: As a co-founder of Tech Solutions Inc., Sarah Johnson leads the company's technical operations. Her deep knowledge of software engineering principles and commitment to excellence have been crucial in establishing the company as a leader in the industry.\n",
    "Together, John Smith and Sarah Johnson founded Tech Solutions Inc. with the aim of providing cutting-edge technology solutions to help businesses thrive in the digital age. Their combined expertise and passion for innovation have been instrumental in the company's success.\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets add some nonesense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_text = \"\"\"\n",
    "There once lived an old man and an old woman who were peasants and had to work hard to earn their daily bread. The old man used to go to fix fences and do other odd jobs for the farmers around, and while he was gone the old woman, his wife, did the work of the house and worked in their own little plot of land.\n",
    "It was always the Monday mornings. It never seemed to happen on Tuesday morning, Wednesday morning, or any other morning during the week. But it happened every Monday morning like clockwork. He mentally prepared himself to once again deal with what was about to happen, but this time he also placed a knife in his pocket just in case.\n",
    "There was nothing to indicate Nancy was going to change the world. She looked like an average girl going to an average high school. It was the fact that everything about her seemed average that would end up becoming her superpower.\n",
    "He wondered if he should disclose the truth to his friends. It would be a risky move. Yes, the truth would make things a lot easier if they all stayed on the same page, but the truth might fracture the group leaving everything in even more of a mess than it was not telling the truth. It was time to decide which way to go.\n",
    "He had three simple rules by which he lived. The first was to never eat blue food. There was nothing in nature that was edible that was blue. People often asked about blueberries, but everyone knows those are actually purple. He understood it was one of the stranger rules to live by, but it had served him well thus far in the 50+ years of his life.\n",
    "He sat staring at the person in the train stopped at the station going in the opposite direction. She sat staring ahead, never noticing that she was being watched. Both trains began to move and he knew that in another timeline or in another universe, they had been happy together.\n",
    "Do you think you're living an ordinary life? You are so mistaken it's difficult to even explain. The mere fact that you exist makes you extraordinary. The odds of you existing are less than winning the lottery, but here you are. Are you going to let this extraordinary opportunity pass?\n",
    "The wave crashed and hit the sandcastle head-on. The sandcastle began to melt under the waves force and as the wave receded, half the sandcastle was gone. The next wave hit, not quite as strong, but still managed to cover the remains of the sandcastle and take more of it away. The third wave, a big one, crashed over the sandcastle completely covering and engulfing it. When it receded, there was no trace the sandcastle ever existed and hours of hard work disappeared forever.\n",
    "There are different types of secrets. She had held onto plenty of them during her life, but this one was different. She found herself holding onto the worst type. It was the type of secret that could gnaw away at your insides if you didn't tell someone about it, but it could end up getting you killed if you did.\n",
    "Welcome to my world. You will be greeted by the unexpected here and your mind will be challenged and expanded in ways that you never thought possible. That is if you are able to survive...\n",
    "\"\"\"\n",
    "\n",
    "select_document += random_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: Memory and Vector Search\n",
    "One very common problem with LLM applications is that we often want to use them to parse through large amounts of text and do things like summarize, search or combine the information in these large context.\n",
    "\n",
    "While context size in models keep expanding, this is presently a large limitation for these models, especially when you want to deploy them at scale.\n",
    "\n",
    "There are many ways to address this, but most are related to something close to adding some form of memory or search to these models.\n",
    "\n",
    "Here is a link to a more [comprehensive list of these techniques](TODO).\n",
    "Here, we'll demonstrate a simple way to use LLM embeddings with a vector database to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import openai\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "class TextSplitter:\n",
    "    def __init__(self, max_tokens_in_chunk: int = 2000, chars_per_token: int = 4, separator=\"\\n\") -> None:\n",
    "        \"\"\" Splits a text input into chunks, staying underneath the max_tokens_in_chunk.\n",
    "\n",
    "        Args:\n",
    "            max_tokens_in_chunk (int, optional): Max number of token to aim for in chunks. Defaults to 2000.\n",
    "            chars_per_token (int, optional): The approximate number of characters per token. Defaults to 4.\n",
    "            separator (str, optional): A preferred separator for chunks. Defaults to \"\\n\".\n",
    "        \"\"\"\n",
    "       \n",
    "        self.max_tokens_in_chunk = max_tokens_in_chunk\n",
    "        self.chars_per_token = chars_per_token\n",
    "        self.separator = separator\n",
    "        chunk_size = int(max_tokens_in_chunk / chars_per_token)\n",
    "        \n",
    "        self.text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=int(chunk_size * 0.2),\n",
    "            length_function=len,\n",
    "        )\n",
    "    \n",
    "    def __call__(self, text: Union[str, List[str]]) -> List[str]:\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        return self.text_splitter.create_documents(text)\n",
    "        \n",
    "class DocRetrival:\n",
    "    def __init__(self, docs: List[str], k: int = 3):\n",
    "        \"\"\"\n",
    "        A wrapper for FAISS that allows for easy document retrieval.\n",
    "        \n",
    "        Args:\n",
    "            docs (List[str]): A list of documents to index.\n",
    "            k (int, optional): The number of documents to return. Defaults to 3.\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.db = FAISS.from_documents(docs, embeddings)\n",
    "        self.retriever = self.db.as_retriever(search_kwargs=dict(k=k))\n",
    "    \n",
    "    def __call__(self,  search_string: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Returns the top k documents that are most similar to the search string.\n",
    "        \n",
    "        Args:\n",
    "            search_string (str): The search string.\n",
    "        \"\"\"\n",
    "        return self.retriever.get_relevant_documents(search_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Docs: 16\n",
      "Total Chars: 5006\n",
      "Num Docs: 2\n",
      "Total Chars: 631\n"
     ]
    }
   ],
   "source": [
    "# Initialize the splitter\n",
    "splitter = TextSplitter()\n",
    "\n",
    "# Split large document into chunks\n",
    "docs = splitter(select_document)\n",
    "print(f'Num Docs: {len(docs)}\\nTotal Chars: {sum([len(doc.page_content) for doc in docs])}')\n",
    "\n",
    "# Initialize the retriever\n",
    "retriver = DocRetrival(docs, k=2)\n",
    "\n",
    "# Get relevant documents\n",
    "docs = retriver(template_prompt)\n",
    "print(f'Num Docs: {len(docs)}\\nTotal Chars: {sum([len(doc.page_content) for doc in docs])}')\n",
    "\n",
    "context = '\\n'.join([doc.page_content for doc in docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Tech Solutions Inc.\n",
      "1. John Smith and Sarah Johnson\n",
      "2. April 12, 2005\n",
      "3. May 25, 2007\n"
     ]
    }
   ],
   "source": [
    "# Froms 05-example-entity-extraction.ipynb\n",
    "prompt = template_prompt.replace('<document>', context)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "chatbot_response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=messages,\n",
    "  temperature=0,\n",
    "  max_tokens=1500,\n",
    ")\n",
    "\n",
    "print(\"0. \" + chatbot_response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
