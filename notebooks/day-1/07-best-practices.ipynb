{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70331ce3",
   "metadata": {},
   "source": [
    "### Day 1 - Prompt Engineering Best Practices\n",
    "\n",
    "In this notebook, we will cover some of the prompt engineering best practices.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51215c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_result(message: str, model: str=\"gpt-4\") -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    chatbot_response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages \n",
    "    )\n",
    "    return chatbot_response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bbffb",
   "metadata": {},
   "source": [
    "### 1. Don't say what not to do, say what to do instead.\n",
    "\n",
    "- Don't say \"Don't make the titles too short\"\n",
    "- Say \"Make the titles at least 5 words long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1378b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(\"Write a list of newspaper headlines. Don't make the titles too short.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(\"Write a list of newspaper headlines. Make the titles at least 5 words long.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4427ec7",
   "metadata": {},
   "source": [
    "### 2. Break Down the Task\n",
    "- Consider each subtask separately - perform prompt chaining\n",
    "- Use chain of thought prompting: Ask the model to think step by step\n",
    "\n",
    "We've covered both of these topics in the previous notebooks but as a recap:\n",
    "\n",
    "- Prompt Chaining: Use the output of a prompt as input for another prompt. For example, get summaries of parts of a very large article. Then get a summary of all these summaries.\n",
    "\n",
    "- Chain of Thought: Make the model elucidate its thought process. This can be achieved by giving it an example where a reasoning is provided alongside the answer, or it can also be done by just ending your prompt with something like \"Lets think step by step\". For example, we can use it to explain why it chose to classify a sentence as a particular sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095777df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"As a tutor, your goal is to help students with their questions and comments. When you get a msg, you must first identify its intent from the following 3 categories: \n",
    "\n",
    "1. Seeking Assistance \n",
    "2. Engaging in Discussion \n",
    "3. Unclear\n",
    "\n",
    "Then, respond to students based on the identified intent using the following guideline. \n",
    "1. Seeking Assistance: When a student seeks assistance, the tutor should respond with empathy and understanding. The tone should be non-judgmental, clear and reassuring, instilling confidence in the student. \n",
    "\n",
    "2. Engaging in Discussion: When a student engages in discussion, the tutor should respond with enthusiasm and active listening. The communication style should be open and collaborative, fostering a dynamic exchange of ideas. \n",
    "\n",
    "3. Unclear: When a student's comment is unclear, the tutor should respond with patience and a desire to clarify. The communication style should be clear and concise, asking follow-up questions to gain a better understanding of the student's needs. \n",
    "\n",
    "Examples: \n",
    "Q: I am very confused and need help.\n",
    "Intent: Seeking Assistance\n",
    "Response: Of course! I'm here to help. Please let me know what you're confused about, and I'll do my best to provide you with the information or clarification you need.\n",
    "\n",
    "Q: üíõüíô\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4cfeba",
   "metadata": {},
   "source": [
    "### 3. Apply constraints to the output space\n",
    "- Customize instructions so they directly mention the type of output you're expecting. Otherwise the model might give you something unrelated like just continuing the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c338fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Identify the named entities in the following sentence.\n",
    "\n",
    "###\n",
    "Text: {text}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(prompt.format(text=\"I want to fly from BLR to YYZ on 23rd May, 2023\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Identify the named entities in the following sentence.\n",
    "The named entities are one of the following: \n",
    "[\"first_name\", \"last_name\", \"date (ISO 8601)\", \"from_location\", \"to_location\"]\n",
    "Return answer as a JSON.\n",
    "\n",
    "###\n",
    "Text: {text}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(prompt.format(text=\"I want to fly from BLR to YYZ on 23rd May, 2023\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011a172",
   "metadata": {},
   "source": [
    "### 4. Instruction template\n",
    "\n",
    "Put instructions at the beginning and separate your input from the context using \"\"\" or ###.\n",
    "\n",
    "Bad Example:\n",
    "```\n",
    "Summarize the text below as a bullet point list of the most important points.\n",
    "{text input here}\n",
    "```\n",
    " \n",
    "Good Example:\n",
    "```\n",
    "Summarize the text below as a bullet point list of the most important points.\n",
    "Text: \"\"\"\n",
    "{text input here}\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97382dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Pizza (English: /ÀàpiÀêts…ô/ PEET-s…ô, Italian: [Ààpittsa], Neapolitan: [Ààpitts…ô]) is a dish of Italian origin consisting of a usually round, flat base of leavened wheat-based dough topped with tomatoes, cheese, and often various other ingredients (such as various types of sausage, anchovies, mushrooms, onions, olives, vegetables, meat, ham, etc.), which is then baked at a high temperature, traditionally in a wood-fired oven.\n",
    "\n",
    "The term pizza was first recorded in the 10th century in a Latin manuscript from the Southern Italian town of Gaeta in Lazio, on the border with Campania. Raffaele Esposito is often considered to be the father of modern pizza. Modern pizza was invented in Naples. In 2009, Neapolitan pizza was registered with the European Union as a Traditional Speciality Guaranteed dish. In 2017, the art of making Neapolitan pizza was added to UNESCO's list of intangible cultural heritage.\n",
    "\n",
    "Pizza and its variants are among the most popular foods in the world. Pizza is sold at a variety of restaurants, including pizzerias (pizza specialty restaurants), Mediterranean restaurants, via delivery, and as street food. In Italy, pizza served in a restaurant is presented unsliced, and is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand. Pizza is also sold in grocery stores in a variety of forms, including frozen or as kits for self-assembly. They are then cooked using a home oven.\n",
    "\n",
    "In 2017, the world pizza market was US$128 billion, and in the US it was $44 billion spread over 76,000 pizzerias. Overall, 13% of the U.S. population aged 2 years and over consumed pizza on any given day.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Summarize the following text in three sentences\n",
    "Text: \\\"\"\"{text}\\\"\"\"\n",
    "\"\"\"\n",
    "prompt = prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f80a4",
   "metadata": {},
   "source": [
    "### 5. Be specific\n",
    "\n",
    "- Be specific about all aspects of your desired result such as outcome, length and format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(\"Write a short poem about OpenAI.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(\"Write a short (2 stanzas) inspiring poem about OpenAI, focusing on the recent DALL-E product launch (DALL-E is a text to image ML model) in the style of Robert Frost.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5caa116",
   "metadata": {},
   "source": [
    "### 6. Prompts change for different models/versions\n",
    "\n",
    "- Simple example: GPT-4 is a lot better than GPT-3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(\"Answer the question only if it is within the context. Context: \\\"42 is an amazing number.\\\" Question: Which star does the Earth revolve around?\\nAnswer Format: question_is_in_context:\\nanswer:\\n\", \"gpt-4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(\"Answer the question only if it is within the context. Context: \\\"42 is an amazing number.\\\" Question: Which star does the Earth revolve around?\\nAnswer Format: question_is_in_context:\\nanswer:\\n\", \"gpt-3.5-turbo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af0997",
   "metadata": {},
   "source": [
    "### 7. Steps against prompt injection\n",
    "\n",
    "Make systems robust and protected against adverserial attacks:\n",
    "- Use curly braces (`{}`) for user input\n",
    "- Separate the inputs with a delimiter\n",
    "- Add text after the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Find the pairwise similarity between the following three sentences:\n",
    "\n",
    "---\n",
    "A: {sentence_a}\n",
    "---\n",
    "B: {sentence_b}\n",
    "---\n",
    "C: {sentence_c}\n",
    "---\n",
    "\n",
    "Answer: \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.format(\n",
    "    sentence_a=\"The cat chased the mouse across the room.\",\n",
    "    sentence_b=\"The feline pursued the rodent through the living area.\",\n",
    "    sentence_c=\"The dog barked at the mailman outside the house.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
