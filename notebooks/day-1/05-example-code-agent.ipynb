{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Examples: Code Generation\n",
    "\n",
    "In this notebook we offer an example of code generation. That is, we use the model to help us in a programming task. Note that we use the text completion APIs here as we do not need to have a conversation with the model. We only give it instructions and expect an answer.\n",
    "\n",
    "We first start with generating SQL based on a given input table. Later in this notebook we also offer some examples for Python generation.\n",
    "\n",
    "References/Further Reading:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup template\n",
    "\n",
    "We setup a template here asking the model to look at a table schema and answer a set of questions. Feel free to customize the questions and schema to your own liking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following SQL table and set of questions, return the queries corresponding to each question. \n",
      "Table: \"\"\"<table>\"\"\"\n",
      " \n",
      "Questions:\n",
      "0. How many employees are in the sales department?\n",
      "1. Which employee earns the most?\n",
      "2. Which is the biggest department?\n"
     ]
    }
   ],
   "source": [
    "table = '<table>'\n",
    "template_prompt=f'''Given the following SQL table and set of questions, return the queries corresponding to each question. \\nTable: \\\"\\\"\\\"{table}\\\"\\\"\\\"\\n \\nQuestions:\\n0. How many employees are in the sales department?\\n1. Which employee earns the most?\\n2. Which is the biggest department?'''\n",
    "print(template_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Input\n",
    "\n",
    "Here we add in the document we want the model to read. Feel free to modify this to a document of your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_table = \"\"\"\n",
    "Employee(id, name, department_id)\n",
    "Department(id, name, address)\n",
    "Salary(employee_id, amount)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "Summarizing text with OpenAI models is pretty simple. We pretty much just send the template (with our document added in) to the Completion API and the output will be the model's attempt at a summary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. How many employees are in the sales department?\n",
      "```sql\n",
      "SELECT COUNT(*) \n",
      "FROM Employee \n",
      "JOIN Department ON Employee.department_id = Department.id \n",
      "WHERE Department.name = 'sales';\n",
      "```\n",
      "\n",
      "1. Which employee earns the most?\n",
      "```sql\n",
      "SELECT Employee.id, Employee.name \n",
      "FROM Employee \n",
      "JOIN Salary ON Employee.id = Salary.employee_id \n",
      "WHERE Salary.amount = (SELECT MAX(amount) FROM Salary);\n",
      "```\n",
      "\n",
      "2. Which is the biggest department?\n",
      "```sql\n",
      "SELECT Department.id, Department.name, COUNT(Employee.id) AS employee_count \n",
      "FROM Department \n",
      "JOIN Employee ON Department.id = Employee.department_id \n",
      "GROUP BY Department.id, Department.name \n",
      "ORDER BY employee_count DESC \n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt = template_prompt.replace('<table>', select_table)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "chatbot_response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=messages,\n",
    "  temperature=0,\n",
    "  max_tokens=1500,\n",
    ")\n",
    "\n",
    "print(chatbot_response.choices[0].message[\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google\n",
    "\n",
    "Summarizing text with PaLM is also trivial. We more or less do the same thing as we did for OpenAI and send the prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. ```\n",
      "SELECT COUNT(*)\n",
      "FROM Employee\n",
      "WHERE department_id = (\n",
      "  SELECT id\n",
      "  FROM Department\n",
      "  WHERE name = 'Sales'\n",
      ")\n",
      "```\n",
      "\n",
      "1. ```\n",
      "SELECT name\n",
      "FROM Employee\n",
      "JOIN Salary\n",
      "ON Employee.id = Salary.employee_id\n",
      "ORDER BY amount DESC\n",
      "LIMIT 1\n",
      "```\n",
      "\n",
      "2. ```\n",
      "SELECT name\n",
      "FROM Department\n",
      "ORDER BY COUNT(*) DESC\n",
      "LIMIT 1\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "prompt = template_prompt.replace('<table>', select_table)\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "response = model.predict(prompt, max_output_tokens=1024)\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the two APIs offer slightly different results. Try playing around with the prompt and see how the results change!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Agent\n",
    "\n",
    "Getting code from an LLM is as simple as asking for it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a Python script that generates prime numbers using the Sieve of Eratosthenes algorithm:\n",
      "\n",
      "```python\n",
      "def generate_primes(limit):\n",
      "    primes = []\n",
      "    sieve = [True] * (limit + 1)\n",
      "    sieve[0] = False\n",
      "    sieve[1] = False\n",
      "\n",
      "    for current_number in range(2, limit + 1):\n",
      "        if sieve[current_number]:\n",
      "            primes.append(current_number)\n",
      "            for multiple in range(current_number * 2, limit + 1, current_number):\n",
      "                sieve[multiple] = False\n",
      "\n",
      "    return primes\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    limit = int(input(\"Enter the limit to generate prime numbers up to: \"))\n",
      "    primes = generate_primes(limit)\n",
      "    print(f\"Prime numbers up to {limit}: {primes}\")\n",
      "```\n",
      "\n",
      "You can run this script, enter a limit, and it will generate all prime numbers up to that limit.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt = \"Write a python script to generate prime numbers.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an agent designed to write python code to answer questions.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "chatbot_response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=messages,\n",
    "  temperature=0,\n",
    "  max_tokens=1500,\n",
    ")\n",
    "\n",
    "print(chatbot_response.choices[0].message[\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google PaLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# This Python script generates prime numbers.\n",
      "\n",
      "# Import the math library.\n",
      "import math\n",
      "\n",
      "# Define a function to check if a number is prime.\n",
      "def is_prime(n):\n",
      "    # Check if the number is 1.\n",
      "    if n == 1:\n",
      "        return False\n",
      "\n",
      "    # Check if the number is 2.\n",
      "    if n == 2:\n",
      "        return True\n",
      "\n",
      "    # Check if the number is divisible by any number from 2 to the square root of the number.\n",
      "    for i in range(2, int(math.sqrt(n)) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "\n",
      "    # The number is prime if it is not divisible by any number from 2 to the square root of the number.\n",
      "    return True\n",
      "\n",
      "# Get the user input.\n",
      "n = int(input(\"Enter a number: \"))\n",
      "\n",
      "# Generate a list of prime numbers from 2 to n.\n",
      "prime_numbers = []\n",
      "for i in range(2, n + 1):\n",
      "    if is_prime(i):\n",
      "        prime_numbers.append(i)\n",
      "\n",
      "# Print the list of prime numbers.\n",
      "print(\"The prime numbers from 2 to {} are:\".format(n))\n",
      "for prime in prime_numbers:\n",
      "    print(prime)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "prompt = \"Write a python script to generate prime numbers.\"\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "response = model.predict(prompt, max_output_tokens=1024)\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-bootcamp-4wh1UwyX-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
