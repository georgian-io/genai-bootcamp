{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9dbf5c2-31b3-43c6-b53d-6b381dd8f817",
   "metadata": {},
   "source": [
    "# Day 1 - Examples: Entity Extraction\n",
    "\n",
    "Entity extraction refers to extracting specific pieces of information from a given document/text. For instance, given a Wikipedia blurb, identify a person's date of birth. Note that we use the text completion APIs here as we do not need to have a conversation with the modell. We only give it instructions and expect an answer.\n",
    "\n",
    "References/Further Reading:\n",
    "\n",
    "OpenAI: The code here is a simplified version of https://github.com/openai/openai-cookbook/blob/main/examples/Entity_extraction_for_long_documents.ipynb\n",
    "\n",
    "PaLM: The code here is based on https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/generative_ai/extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224ee96e-da77-498c-ba86-fa80539c3892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "119855df-5073-4291-b943-d14f6168712b",
   "metadata": {},
   "source": [
    "## Setup template\n",
    "\n",
    "We setup a template here asking the model to extract the information we want from a given document. We can then replace different documents into this template and acquire that information at each point. Note the ending \"0.\". This helps the model to understand that we want it to answer point by point, starting with point 0. Feel free to customize the questions to your liking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81957b32-3eb9-43a2-abc7-a3945520851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract key pieces of information from this regulation document.\n",
      "If a particular piece of information is not present, output \"Not specified\".\n",
      "When you extract a key piece of information, include the closest page number.\n",
      "Use the following format:\n",
      "0. What's the name of the company?\n",
      "1. Who are the founders of the company?\n",
      "2. When is it founded?\n",
      "3. When did it raise series A?\n",
      "Document: \"\"\"<document>\"\"\"\n",
      "\n",
      "0.\n"
     ]
    }
   ],
   "source": [
    "document = '<document>'\n",
    "template_prompt=f'''Extract key pieces of information from this regulation document.\n",
    "If a particular piece of information is not present, output \\\"Not specified\\\".\n",
    "When you extract a key piece of information, include the closest page number.\n",
    "Use the following format:\\n0. What's the name of the company?\\n1. Who are the founders of the company?\\n2. When is it founded?\\n3. When did it raise series A?\\nDocument: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\\n0.'''\n",
    "print(template_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44540106-c7db-43ea-9876-cd1fb4cc0e4c",
   "metadata": {},
   "source": [
    "#### User Input\n",
    "\n",
    "Here we add in the document we want the model to read. Feel free to modify this to a document of your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da93baef-cc8e-45d7-a1de-b63cb697795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_document = \"\"\"\n",
    "Overview:\n",
    "Tech Solutions Inc. is a leading technology consulting firm specializing in providing innovative solutions to businesses across various industries. We offer a comprehensive range of services including software development, IT consulting, project management, and cybersecurity solutions. \n",
    "With a strong focus on delivering exceptional quality and customer satisfaction, we have established ourselves as a trusted partner for organizations seeking digital transformation.\n",
    "They were founded on April 12, 2005 and raise their first seed in 2007 and series A on May 25, 2007.\n",
    "\n",
    "Founders:\n",
    "\n",
    "Background: John Smith is a visionary entrepreneur with over 20 years of experience in the technology industry. He has a deep understanding of market trends and has successfully led several software development projects for multinational corporations.\n",
    "Role in the Company: As a co-founder of Tech Solutions Inc., John Smith plays a pivotal role in shaping the company's strategic direction. His expertise in software development and leadership skills have been instrumental in driving the company's growth.\n",
    "Sarah Johnson:\n",
    "\n",
    "Background: Sarah Johnson is a highly accomplished technologist with a strong background in software engineering. She has extensive experience in managing complex IT projects and has a proven track record of delivering innovative solutions.\n",
    "Role in the Company: As a co-founder of Tech Solutions Inc., Sarah Johnson leads the company's technical operations. Her deep knowledge of software engineering principles and commitment to excellence have been crucial in establishing the company as a leader in the industry.\n",
    "Together, John Smith and Sarah Johnson founded Tech Solutions Inc. with the aim of providing cutting-edge technology solutions to help businesses thrive in the digital age. Their combined expertise and passion for innovation have been instrumental in the company's success.\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e95dbc87",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "Extracting entities with OpenAI is pretty simple. We pretty much just send the template (with our document added in) to the Completion API and the output will be what the model thinks are the answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f1bfc1-5846-42dd-9202-e634e6d66e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. What's the name of the company?\n",
      "Tech Solutions Inc.\n",
      "\n",
      "1. Who are the founders of the company?\n",
      "John Smith and Sarah Johnson (Page 1)\n",
      "\n",
      "2. When is it founded?\n",
      "April 12, 2005 (Page 1)\n",
      "\n",
      "3. When did it raise series A?\n",
      "May 25, 2007 (Page 1)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "prompt = template_prompt.replace('<document>',select_document)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model='text-davinci-003', \n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=1500,\n",
    ")\n",
    "print(\"0.\" + response['choices'][0]['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e96817d",
   "metadata": {},
   "source": [
    "## PaLM\n",
    "\n",
    "Extracting entities with PaLM is also trivial. We more or less do the same thing as we did for OpenAI and send the prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbde8ebc-330f-4948-89dc-e3f483c910a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the company is Tech Solutions Inc.\n",
      "1. The founders of the company are John Smith and Sarah Johnson.\n",
      "2. The company was founded on April 12, 2005.\n",
      "3. The company raised series A on May 25, 2007.\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "prompt = template_prompt.replace('<document>',select_document)\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "response = model.predict(prompt, max_output_tokens=1024)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
